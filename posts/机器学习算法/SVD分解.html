<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-beta.67" />
    <meta name="theme" content="VuePress Theme Hope" />
    <meta property="og:url" content="https://GSpotMan.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/SVD%E5%88%86%E8%A7%A3.html"><meta property="og:site_name" content="Lzy"><meta property="og:title" content="SVD分解和PCA主成分析"><meta property="og:description" content="SVD分解和PCA主成分析 奇异值分解（Singular Value Decomposition，简称SVD）是一种常用的矩阵分解方法，用于将一个矩阵分解为三个矩阵的乘积。SVD在许多领域中都有广泛的应用，如数据降维、图像压缩、推荐系统等。 数学公式表示 SVD的数学公式表示如下： 给定一个 m×nm×nm×n 的矩阵AAA，其SVD表示为："><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2023-10-09T10:08:51.000Z"><meta property="article:author" content="Lzy"><meta property="article:tag" content="svd"><meta property="article:tag" content="pca"><meta property="article:published_time" content="2023-09-23T00:00:00.000Z"><meta property="article:modified_time" content="2023-10-09T10:08:51.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"SVD分解和PCA主成分析","image":[""],"datePublished":"2023-09-23T00:00:00.000Z","dateModified":"2023-10-09T10:08:51.000Z","author":[{"@type":"Person","name":"Lzy","url":"https://GSpotMan.com"}]}</script><link rel="icon" href="/touxiang.jpg"><title>SVD分解和PCA主成分析 | Lzy</title><meta name="description" content="SVD分解和PCA主成分析 奇异值分解（Singular Value Decomposition，简称SVD）是一种常用的矩阵分解方法，用于将一个矩阵分解为三个矩阵的乘积。SVD在许多领域中都有广泛的应用，如数据降维、图像压缩、推荐系统等。 数学公式表示 SVD的数学公式表示如下： 给定一个 m×nm×nm×n 的矩阵AAA，其SVD表示为：">
    <style>
      :root {
        --bg-color: #fff;
      }

      html[data-theme="dark"] {
        --bg-color: #1d1e1f;
      }

      html,
      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="preload" href="/assets/style-a9d648ac.css" as="style"><link rel="stylesheet" href="/assets/style-a9d648ac.css">
    <link rel="modulepreload" href="/assets/app-6cc7be11.js"><link rel="modulepreload" href="/assets/SVD分解.html-597e8cf2.js"><link rel="modulepreload" href="/assets/SVD分解.html-acecd4d4.js"><link rel="prefetch" href="/assets/index.html-51c3b238.js" as="script"><link rel="prefetch" href="/assets/算法基础.html-6d1b4daa.js" as="script"><link rel="prefetch" href="/assets/机器学习基础.html-8bcfc9de.js" as="script"><link rel="prefetch" href="/assets/AlexNet.html-87892c03.js" as="script"><link rel="prefetch" href="/assets/GoogLeNet.html-eeb42712.js" as="script"><link rel="prefetch" href="/assets/LeNet.html-e6841bca.js" as="script"><link rel="prefetch" href="/assets/ResNet.html-176d3905.js" as="script"><link rel="prefetch" href="/assets/VGGNet.html-f24b478f.js" as="script"><link rel="prefetch" href="/assets/共轭梯度法.html-66123e13.js" as="script"><link rel="prefetch" href="/assets/线性方程组求解(迭代法).html-5db1d339.js" as="script"><link rel="prefetch" href="/assets/线性方程组求解.html-ac35e1c1.js" as="script"><link rel="prefetch" href="/assets/迭代法求特征值.html-be73797d.js" as="script"><link rel="prefetch" href="/assets/404.html-bfaeb449.js" as="script"><link rel="prefetch" href="/assets/index.html-a98a1e31.js" as="script"><link rel="prefetch" href="/assets/index.html-19d6a7a7.js" as="script"><link rel="prefetch" href="/assets/index.html-81fd4c87.js" as="script"><link rel="prefetch" href="/assets/index.html-d5e8824c.js" as="script"><link rel="prefetch" href="/assets/index.html-69856ab1.js" as="script"><link rel="prefetch" href="/assets/index.html-69a62fab.js" as="script"><link rel="prefetch" href="/assets/index.html-846c5704.js" as="script"><link rel="prefetch" href="/assets/index.html-5d87a892.js" as="script"><link rel="prefetch" href="/assets/index.html-d77152a9.js" as="script"><link rel="prefetch" href="/assets/index.html-6ce418cd.js" as="script"><link rel="prefetch" href="/assets/index.html-de60391c.js" as="script"><link rel="prefetch" href="/assets/index.html-62b65814.js" as="script"><link rel="prefetch" href="/assets/index.html-1186127c.js" as="script"><link rel="prefetch" href="/assets/index.html-9c075c4a.js" as="script"><link rel="prefetch" href="/assets/index.html-6eb7e6aa.js" as="script"><link rel="prefetch" href="/assets/index.html-0c06eb31.js" as="script"><link rel="prefetch" href="/assets/index.html-b63f80ab.js" as="script"><link rel="prefetch" href="/assets/index.html-42061e1a.js" as="script"><link rel="prefetch" href="/assets/index.html-d4377b69.js" as="script"><link rel="prefetch" href="/assets/index.html-02bc290e.js" as="script"><link rel="prefetch" href="/assets/index.html-1265835c.js" as="script"><link rel="prefetch" href="/assets/index.html-2752d771.js" as="script"><link rel="prefetch" href="/assets/index.html-03758434.js" as="script"><link rel="prefetch" href="/assets/index.html-9a0f3fcc.js" as="script"><link rel="prefetch" href="/assets/index.html-ac5f80e2.js" as="script"><link rel="prefetch" href="/assets/index.html-c715ba10.js" as="script"><link rel="prefetch" href="/assets/index.html-09b50fad.js" as="script"><link rel="prefetch" href="/assets/index.html-608110dd.js" as="script"><link rel="prefetch" href="/assets/index.html-6d241be4.js" as="script"><link rel="prefetch" href="/assets/算法基础.html-112df1ab.js" as="script"><link rel="prefetch" href="/assets/机器学习基础.html-63c801e9.js" as="script"><link rel="prefetch" href="/assets/AlexNet.html-a0c678a4.js" as="script"><link rel="prefetch" href="/assets/GoogLeNet.html-44da0790.js" as="script"><link rel="prefetch" href="/assets/LeNet.html-8255db6b.js" as="script"><link rel="prefetch" href="/assets/ResNet.html-d483d685.js" as="script"><link rel="prefetch" href="/assets/VGGNet.html-746dd7a6.js" as="script"><link rel="prefetch" href="/assets/共轭梯度法.html-ed373daa.js" as="script"><link rel="prefetch" href="/assets/线性方程组求解(迭代法).html-3eb81d7a.js" as="script"><link rel="prefetch" href="/assets/线性方程组求解.html-f2c41b6b.js" as="script"><link rel="prefetch" href="/assets/迭代法求特征值.html-a5e478f4.js" as="script"><link rel="prefetch" href="/assets/404.html-bde2d779.js" as="script"><link rel="prefetch" href="/assets/index.html-3a04b124.js" as="script"><link rel="prefetch" href="/assets/index.html-9afb6c59.js" as="script"><link rel="prefetch" href="/assets/index.html-e645d270.js" as="script"><link rel="prefetch" href="/assets/index.html-bdd9663d.js" as="script"><link rel="prefetch" href="/assets/index.html-29be2328.js" as="script"><link rel="prefetch" href="/assets/index.html-f200c238.js" as="script"><link rel="prefetch" href="/assets/index.html-fa74a897.js" as="script"><link rel="prefetch" href="/assets/index.html-12d2addc.js" as="script"><link rel="prefetch" href="/assets/index.html-59beb68a.js" as="script"><link rel="prefetch" href="/assets/index.html-6218071a.js" as="script"><link rel="prefetch" href="/assets/index.html-87af01d5.js" as="script"><link rel="prefetch" href="/assets/index.html-91d9fb5c.js" as="script"><link rel="prefetch" href="/assets/index.html-09973a39.js" as="script"><link rel="prefetch" href="/assets/index.html-ee113712.js" as="script"><link rel="prefetch" href="/assets/index.html-3cac2a07.js" as="script"><link rel="prefetch" href="/assets/index.html-cf6d17c7.js" as="script"><link rel="prefetch" href="/assets/index.html-fe5b1a61.js" as="script"><link rel="prefetch" href="/assets/index.html-5e661677.js" as="script"><link rel="prefetch" href="/assets/index.html-d69d1d23.js" as="script"><link rel="prefetch" href="/assets/index.html-bcbddad5.js" as="script"><link rel="prefetch" href="/assets/index.html-af326d7a.js" as="script"><link rel="prefetch" href="/assets/index.html-c2b8b525.js" as="script"><link rel="prefetch" href="/assets/index.html-adeec60d.js" as="script"><link rel="prefetch" href="/assets/index.html-6b3952e7.js" as="script"><link rel="prefetch" href="/assets/index.html-9d85f39f.js" as="script"><link rel="prefetch" href="/assets/index.html-2f856bcb.js" as="script"><link rel="prefetch" href="/assets/index.html-a4119561.js" as="script"><link rel="prefetch" href="/assets/index.html-29e40777.js" as="script"><link rel="prefetch" href="/assets/auto-fe80bb03.js" as="script"><link rel="prefetch" href="/assets/index-2bf332f6.js" as="script"><link rel="prefetch" href="/assets/flowchart-c441f34d.js" as="script"><link rel="prefetch" href="/assets/mermaid.core-fc752c56.js" as="script"><link rel="prefetch" href="/assets/highlight.esm-75b11b9d.js" as="script"><link rel="prefetch" href="/assets/markdown.esm-9d5bc2ce.js" as="script"><link rel="prefetch" href="/assets/math.esm-70a288c8.js" as="script"><link rel="prefetch" href="/assets/notes.esm-a106bb2c.js" as="script"><link rel="prefetch" href="/assets/reveal.esm-1a4c3ae7.js" as="script"><link rel="prefetch" href="/assets/search.esm-7e6792e2.js" as="script"><link rel="prefetch" href="/assets/zoom.esm-b83b91d0.js" as="script"><link rel="prefetch" href="/assets/VuePlayground-08dab4bb.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-5762295a.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="vp-link vp-brand vp-brand" href="/"><img class="vp-nav-logo" src="/00000.png" alt="Lzy"><!----><span class="vp-site-name hide-in-pad">Lzy</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><a aria-label="主页" class="vp-link nav-link nav-link" href="/"><span class="font-icon icon fa-fw fa-sm fas fa-home" style=""></span>主页<!----></a></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="机器学习"><span class="title"><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span>机器学习</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><h4 class="dropdown-subtitle"><span>机器学习算法</span></h4><ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a aria-label="机器学习基础" class="vp-link nav-link nav-link" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.html"><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span>机器学习基础<!----></a></li><li class="dropdown-subitem"><a aria-label="SVD分解和PCA主成分析" class="vp-link nav-link active nav-link active" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/SVD%E5%88%86%E8%A7%A3.html"><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span>SVD分解和PCA主成分析<!----></a></li></ul></li><li class="dropdown-item"><h4 class="dropdown-subtitle"><span>网络模型</span></h4><ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a aria-label="LeNet" class="vp-link nav-link nav-link" href="/posts/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/LeNet.html"><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span>LeNet<!----></a></li><li class="dropdown-subitem"><a aria-label="AlexNet" class="vp-link nav-link nav-link" href="/posts/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/AlexNet.html"><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span>AlexNet<!----></a></li><li class="dropdown-subitem"><a aria-label="VGGNet" class="vp-link nav-link nav-link" href="/posts/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/VGGNet.html"><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span>VGGNet<!----></a></li><li class="dropdown-subitem"><a aria-label="GoogLeNet" class="vp-link nav-link nav-link" href="/posts/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/GoogLeNet.html"><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span>GoogLeNet<!----></a></li><li class="dropdown-subitem"><a aria-label="ResNet" class="vp-link nav-link nav-link" href="/posts/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/ResNet.html"><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span>ResNet<!----></a></li></ul></li></ul></button></div></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="课程学习"><span class="title"><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span>课程学习</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><h4 class="dropdown-subtitle"><span>数值分析</span></h4><ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a aria-label="LU分解" class="vp-link nav-link nav-link" href="/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84%E6%B1%82%E8%A7%A3.html"><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span>LU分解<!----></a></li><li class="dropdown-subitem"><a aria-label="线性方程组求解(迭代法)" class="vp-link nav-link nav-link" href="/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84%E6%B1%82%E8%A7%A3(%E8%BF%AD%E4%BB%A3%E6%B3%95).html"><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span>线性方程组求解(迭代法)<!----></a></li><li class="dropdown-subitem"><a aria-label="共轭梯度法" class="vp-link nav-link nav-link" href="/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/%E5%85%B1%E8%BD%AD%E6%A2%AF%E5%BA%A6%E6%B3%95.html"><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span>共轭梯度法<!----></a></li><li class="dropdown-subitem"><a aria-label="迭代求特征值" class="vp-link nav-link nav-link" href="/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/%E8%BF%AD%E4%BB%A3%E6%B3%95%E6%B1%82%E7%89%B9%E5%BE%81%E5%80%BC.html"><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span>迭代求特征值<!----></a></li></ul></li></ul></button></div></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="目标检测"><span class="title"><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span>目标检测</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a aria-label="算法基础" class="vp-link nav-link nav-link" href="/算法基础.html"><!---->算法基础<!----></a></li></ul></button></div></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><!----><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://github.com/GSPotMan/my-doc" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button type="button" class="outlook-button" tabindex="-1" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" class="icon outlook-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="outlook icon"><path d="M224 800c0 9.6 3.2 44.8 6.4 54.4 6.4 48-48 76.8-48 76.8s80 41.6 147.2 0 134.4-134.4 38.4-195.2c-22.4-12.8-41.6-19.2-57.6-19.2C259.2 716.8 227.2 761.6 224 800zM560 675.2l-32 51.2c-51.2 51.2-83.2 32-83.2 32 25.6 67.2 0 112-12.8 128 25.6 6.4 51.2 9.6 80 9.6 54.4 0 102.4-9.6 150.4-32l0 0c3.2 0 3.2-3.2 3.2-3.2 22.4-16 12.8-35.2 6.4-44.8-9.6-12.8-12.8-25.6-12.8-41.6 0-54.4 60.8-99.2 137.6-99.2 6.4 0 12.8 0 22.4 0 12.8 0 38.4 9.6 48-25.6 0-3.2 0-3.2 3.2-6.4 0-3.2 3.2-6.4 3.2-6.4 6.4-16 6.4-16 6.4-19.2 9.6-35.2 16-73.6 16-115.2 0-105.6-41.6-198.4-108.8-268.8C704 396.8 560 675.2 560 675.2zM224 419.2c0-28.8 22.4-51.2 51.2-51.2 28.8 0 51.2 22.4 51.2 51.2 0 28.8-22.4 51.2-51.2 51.2C246.4 470.4 224 448 224 419.2zM320 284.8c0-22.4 19.2-41.6 41.6-41.6 22.4 0 41.6 19.2 41.6 41.6 0 22.4-19.2 41.6-41.6 41.6C339.2 326.4 320 307.2 320 284.8zM457.6 208c0-12.8 12.8-25.6 25.6-25.6 12.8 0 25.6 12.8 25.6 25.6 0 12.8-12.8 25.6-25.6 25.6C470.4 233.6 457.6 220.8 457.6 208zM128 505.6C128 592 153.6 672 201.6 736c28.8-60.8 112-60.8 124.8-60.8-16-51.2 16-99.2 16-99.2l316.8-422.4c-48-19.2-99.2-32-150.4-32C297.6 118.4 128 291.2 128 505.6zM764.8 86.4c-22.4 19.2-390.4 518.4-390.4 518.4-22.4 28.8-12.8 76.8 22.4 99.2l9.6 6.4c35.2 22.4 80 12.8 99.2-25.6 0 0 6.4-12.8 9.6-19.2 54.4-105.6 275.2-524.8 288-553.6 6.4-19.2-3.2-32-19.2-32C777.6 76.8 771.2 80 764.8 86.4z"></path></svg><div class="outlook-dropdown"><!----></div></button></div><!----><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"><li><!--[--><a aria-label="主页" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/"><span class="font-icon icon fa-fw fa-sm fas fa-home" style=""></span>主页<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-heading clickable"><span class="font-icon icon fa-fw fa-sm fas fa-laptop-code" style=""></span><a aria-label="课程学习" class="vp-link nav-link vp-sidebar-title nav-link vp-sidebar-title" href="/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"><!---->课程学习<!----></a><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-heading clickable" type="button"><!----><span class="vp-sidebar-title">数值分析</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-heading clickable active"><span class="font-icon icon fa-fw fa-sm fas fa-book" style=""></span><a aria-label="机器学习" class="vp-link nav-link active vp-sidebar-title nav-link active vp-sidebar-title" href="/posts/"><!---->机器学习<!----></a><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-heading clickable active" type="button"><!----><span class="vp-sidebar-title">机器学习算法</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><!--[--><a aria-label="机器学习基础" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.html"><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span>机器学习基础<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="SVD分解和PCA主成分析" class="vp-link nav-link active vp-sidebar-link vp-sidebar-page active nav-link active vp-sidebar-link vp-sidebar-page active" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/SVD%E5%88%86%E8%A7%A3.html"><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span>SVD分解和PCA主成分析<!----></a><ul class="vp-sidebar-sub-headers"><li class="vp-sidebar-sub-header"><a aria-label="数学公式表示" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/SVD%E5%88%86%E8%A7%A3.html#数学公式表示"><!---->数学公式表示<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="几何意义" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/SVD%E5%88%86%E8%A7%A3.html#几何意义"><!---->几何意义<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="SVD算法步骤" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/SVD%E5%88%86%E8%A7%A3.html#svd算法步骤"><!---->SVD算法步骤<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="图像压缩算法实现" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/SVD%E5%88%86%E8%A7%A3.html#图像压缩算法实现"><!---->图像压缩算法实现<!----></a><ul class="vp-sidebar-sub-headers"><li class="vp-sidebar-sub-header"><a aria-label="方法一" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/SVD%E5%88%86%E8%A7%A3.html#方法一"><!---->方法一<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="方法二" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/SVD%E5%88%86%E8%A7%A3.html#方法二"><!---->方法二<!----></a><ul class="vp-sidebar-sub-headers"></ul></li></ul></li><li class="vp-sidebar-sub-header"><a aria-label="数学公式表示" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/SVD%E5%88%86%E8%A7%A3.html#数学公式表示-1"><!---->数学公式表示<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="几何意义" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/SVD%E5%88%86%E8%A7%A3.html#几何意义-1"><!---->几何意义<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="图像压缩算法实现" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/SVD%E5%88%86%E8%A7%A3.html#图像压缩算法实现-1"><!---->图像压缩算法实现<!----></a><ul class="vp-sidebar-sub-headers"></ul></li></ul><!--]--></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-heading clickable" type="button"><!----><span class="vp-sidebar-title">网络模型</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-heading"><span class="font-icon icon fa-fw fa-sm fas fa-book" style=""></span><span class="vp-sidebar-title">目标检测</span><!----></p><ul class="vp-sidebar-links"><li><!--[--><a aria-label="算法基础" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80.html"><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span>算法基础<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li></ul></section></li></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span>SVD分解和PCA主成分析</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://GSpotMan.com" target="_blank" rel="noopener noreferrer">Lzy</a></span><span property="author" content="Lzy"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2023-09-23T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 10 分钟</span><meta property="timeRequired" content="PT10M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category6 clickable" role="navigation">机器学习算法</span><!--]--><meta property="articleSection" content="机器学习算法"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag0 clickable" role="navigation">svd</span><span class="page-tag-item tag5 clickable" role="navigation">pca</span><!--]--><meta property="keywords" content="svd,pca"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">此页内容<button type="button" class="print-button" title="打印"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#数学公式表示">数学公式表示</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#几何意义">几何意义</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#svd算法步骤">SVD算法步骤</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#图像压缩算法实现">图像压缩算法实现</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#方法一">方法一</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#方法二">方法二</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#数学公式表示-1">数学公式表示</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#几何意义-1">几何意义</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#图像压缩算法实现-1">图像压缩算法实现</a></li><!----><!--]--></ul><div class="toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!----><div class="theme-hope-content"><h1 id="svd分解和pca主成分析" tabindex="-1"><a class="header-anchor" href="#svd分解和pca主成分析" aria-hidden="true">#</a> SVD分解和PCA主成分析</h1><p>奇异值分解（Singular Value Decomposition，简称SVD）是一种常用的矩阵分解方法，用于将一个矩阵分解为三个矩阵的乘积。SVD在许多领域中都有广泛的应用，如数据降维、图像压缩、推荐系统等。</p><h2 id="数学公式表示" tabindex="-1"><a class="header-anchor" href="#数学公式表示" aria-hidden="true">#</a> 数学公式表示</h2><p>SVD的数学公式表示如下：<br> 给定一个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>×</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">m×n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span> 的矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span>，其SVD表示为：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mo>=</mo><mi>U</mi><mi mathvariant="normal">Σ</mi><msup><mi>V</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex"> A = U \Sigma V^T </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8913em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord">Σ</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi></mrow><annotation encoding="application/x-tex">U</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span></span></span></span>是一个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>×</mo><mi>m</mi></mrow><annotation encoding="application/x-tex">m \times m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">m</span></span></span></span>的酉矩阵，表示<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><msup><mi>A</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">AA^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord mathnormal">A</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span>的特征向量构成的矩阵；<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Σ</mi></mrow><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Σ</span></span></span></span>是一个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>×</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">m \times n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span>的对角矩阵，表示<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span>的奇异值构成的矩阵；<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span>是一个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>×</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">n \times n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span>的酉矩阵，表示<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mi>T</mi></msup><mi>A</mi></mrow><annotation encoding="application/x-tex">A^TA</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord mathnormal">A</span></span></span></span>的特征向量构成的矩阵。</p><h2 id="几何意义" tabindex="-1"><a class="header-anchor" href="#几何意义" aria-hidden="true">#</a> 几何意义</h2><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi></mrow><annotation encoding="application/x-tex">U</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span></span></span></span>是一个正交矩阵，表示旋转操作；<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Σ</mi></mrow><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Σ</span></span></span></span>是一个对角矩阵，表示缩放操作；<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span>是另一个正交矩阵，表示再旋转操作。</p><p>具体而言，SVD的几何意义可以解释如下：</p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi></mrow><annotation encoding="application/x-tex">U</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span></span></span></span>表示将原始空间中的向量旋转到一个新的坐标系中。这个新坐标系的基向量是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi></mrow><annotation encoding="application/x-tex">U</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span></span></span></span>的列向量，它们是原始坐标系中的标准正交基向量的旋转版本。</p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Σ</mi></mrow><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Σ</span></span></span></span>表示在每个坐标轴上的缩放因子。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Σ</mi></mrow><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Σ</span></span></span></span>的对角线上的元素称为奇异值，它们表示原始向量在每个旋转后的坐标轴上的缩放程度。奇异值按照降序排列，因此，前面的奇异值对应着更重要的特征。</p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span>表示将旋转后的向量再次旋转回原始坐标系。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span>的列向量是原始坐标系中的标准正交基向量的再旋转版本。</p><p>总的来说是将一个矩阵通过旋转，拉伸，再旋转，而拉伸即用中间的奇异值矩阵进行表示。通过SVD，我们可以将一个矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 表示为一系列几何操作的组合，从而揭示了原始数据的主要几何特征。SVD在降维、信号处理、图像压缩等领域中具有广泛的应用，可以提取数据的重要特征、去除噪声和冗余信息，并帮助理解数据的结构和模式。</p><h2 id="svd算法步骤" tabindex="-1"><a class="header-anchor" href="#svd算法步骤" aria-hidden="true">#</a> SVD算法步骤</h2><p>SVD算法的基本步骤如下：</p><ol><li>给定一个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>×</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">m \times n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span>的矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span>，其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">m</span></span></span></span>是行数，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span>是列数。</li><li>计算<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span>的转置矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">A^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span>与<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span>的乘积<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><msup><mi>A</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">AA^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord mathnormal">A</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span>。</li><li>对<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><msup><mi>A</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">AA^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord mathnormal">A</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span>进行特征值分解，得到特征值和特征向量。</li><li>计算<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">A^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span>的转置矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msup><mi>A</mi><mi>T</mi></msup><msup><mo stretchy="false">)</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">(A^T)^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0913em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span>与<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">A^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span>的乘积<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mi>T</mi></msup><mi>A</mi></mrow><annotation encoding="application/x-tex">A^TA</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord mathnormal">A</span></span></span></span>。</li><li>对<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mi>T</mi></msup><mi>A</mi></mrow><annotation encoding="application/x-tex">A^TA</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord mathnormal">A</span></span></span></span>进行特征值分解，得到特征值和特征向量。</li><li>根据特征值和特征向量构建奇异值矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Σ</mi></mrow><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Σ</span></span></span></span>。</li><li>对<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span>进行奇异值分解，得到矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi></mrow><annotation encoding="application/x-tex">U</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Σ</mi></mrow><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Σ</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span>。</li></ol><h2 id="图像压缩算法实现" tabindex="-1"><a class="header-anchor" href="#图像压缩算法实现" aria-hidden="true">#</a> 图像压缩算法实现</h2><p>这里主要使用python实现对目标图片进行压缩。通过查阅相关资料了解到可以通过使用pytorch中的svd函数进行实现，<br> 也可以通过使用python中numpy库中线性代数相关的函数进行分解，这里选择采用第二种方式。其次这次试验要求<br> 处理的图像为一张图像，因此转化为张量形式之后三维的，通道深度为3，分别表示红绿蓝三色。而传统的SVD分解算法<br> 则只能处理二维矩阵形式，也就是灰度图。因此考虑到两种方法对其进行分解，一种是将3维张量reshape成2维，<br> 在进行相关压缩之后再reshape回来。第二种方法是对3个通道分别进行SVD分解，然后再把三个通道叠加成三维张量<br> 的形式。</p><h3 id="方法一" tabindex="-1"><a class="header-anchor" href="#方法一" aria-hidden="true">#</a> 方法一</h3><p>方法一将3维张量reshape成2维，在进行相关压缩之后再reshape回来，并使用pytorch中的SVD函数进行处理。<br> 代码如下：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>import numpy as np
import matplotlib.pyplot as plt
import torch

# 读取图片
imag = plt.imread(&#39;butterfly.bmp&#39;)

tensor_image = torch.tensor(imag)
reshaped_image = tensor_image.reshape(-1,437)
float_image = reshaped_image.float()
U, S, V = torch.svd(float_image)

# 误差
errors=[]

# 按照奇异值数量倒序进行图片展示，每次减少25个奇异值
for k in range(len(S), 0, -25):
# 分解

      compressed_S = np.diag(S[:k])
      compressed_U = U[:, :k]
      compressed_V= V[:k, :]
  
  
      # 计算
      reconstructed_array = np.dot(compressed_U, np.dot(compressed_S, compressed_V))
      
  
      # 回滚
      reconstructed_image_array = reconstructed_array.reshape(imag.shape)
      reconstructed_image = reconstructed_image_array.astype(np.uint8)
      
      # 误差分析
      diff = imag - reconstructed_image
      mse = np.mean(np.square(diff))
      errors.append(mse)
      
      # # 图片展示,如需要可以将注释打开
      # plt.imshow(reconstructed_image)
      # plt.show()

# 误差分析
plt.plot(range(len(S), 0, -25),errors)
plt.xlabel(&#39;奇异值数&#39;,fontproperties=&#39;SimHei&#39;)
plt.ylabel(&#39;均方误差&#39;,fontproperties=&#39;SimHei&#39;)
plt.show()
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>下面分别为误差图和压缩图：<br><img src="/assets/image-f99209f6.png" alt="Alt text" loading="lazy"><br> 可以看到如果先将三维张量压缩为二维在进行SVD分解，之后再还原成三维的方法是不行的。造成这种结果的原因<br> 可能是在将三个通道压缩成一个通道之后，奇异值所代表的特征是三个通道叠加的，在进行相关压缩之后再reshape回来后<br> 就会出现一些错误。</p><h3 id="方法二" tabindex="-1"><a class="header-anchor" href="#方法二" aria-hidden="true">#</a> 方法二</h3><p>第二种方法是对3个通道分别进行SVD分解，采用的是numpy库中关于线性代数的相关函数。把三个通道拆分为R，G，B,对三个<br> 不同的矩阵分别处理，之后再叠加，代码如下：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>import numpy as np
import matplotlib.pyplot as plt

# 读取图片
imag = plt.imread(&#39;butterfly.bmp&#39;)

# 图片深度是3，拆分为深度1的3个矩阵分别进行分解
red_channel = imag[:, :, 0]
green_channel = imag[:, :, 1]
blue_channel = imag[:, :, 2]

# 进行分解
U_red, S_red, V_red = np.linalg.svd(red_channel)
U_green, S_green, V_green = np.linalg.svd(green_channel)
U_blue, S_blue, V_blue = np.linalg.svd(blue_channel)

# 误差
errors=[]

# 按照奇异值数量倒序进行图片展示，每次减少25个奇异值
for k in range(len(U_red), 0, -25):
# 分解三个深度
compressed_S_red = np.diag(S_red[:k])
compressed_S_green = np.diag(S_green[:k])
compressed_S_blue = np.diag(S_blue[:k])
# UV分解
compressed_U_red = U_red[:, :k]
compressed_V_red = V_red[:k, :]
compressed_U_green = U_green[:, :k]
compressed_V_green = V_green[:k, :]
compressed_U_blue = U_blue[:, :k]
compressed_V_blue = V_blue[:k, :]
# 计算
compressed_red_channel = np.dot(compressed_U_red, np.dot(compressed_S_red, compressed_V_red))
compressed_green_channel = np.dot(compressed_U_green, np.dot(compressed_S_green, compressed_V_green))
compressed_blue_channel = np.dot(compressed_U_blue, np.dot(compressed_S_blue, compressed_V_blue))
# 合并三个深度
compressed_imag = np.stack([compressed_red_channel, compressed_green_channel, compressed_blue_channel], axis=2)
compressed_imag = compressed_imag.astype(np.uint8)
# 误差分析
diff = imag - compressed_imag
mse = np.mean(np.square(diff))
errors.append(mse)
# # 图片展示,如需要可以将注释打开
# plt.imshow(compressed_imag)
# plt.show()
#误差分析
plt.plot(range(len(U_red), 0, -25),errors)
plt.xlabel(&#39;奇异值数&#39;,fontproperties=&#39;SimHei&#39;)
plt.ylabel(&#39;均方误差&#39;,fontproperties=&#39;SimHei&#39;)
plt.show()
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>下面为第二次的误差图：</p><figure><img src="/assets/image-1-6907744c.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>该误差图是将奇异值从大到小进行排序后，依次减少25个奇异值并分析其误差画出来的<br> 折线图，可以看出在初期减少奇异值的时候误差变化并不大，原因在于刚开始减小的是一些<br> 数值比较小的奇异值，可以解释为这些奇异值对该图像的特征并没什么影响。</p><p>下面为第二次压缩图像：<br><img src="/assets/image-2-d9903e77.png" alt="" loading="lazy"></p><h1 id="pca主成分分析" tabindex="-1"><a class="header-anchor" href="#pca主成分分析" aria-hidden="true">#</a> PCA主成分分析</h1><p>主成分分析（Principal Component Analysis，简称PCA）是一种常用的数据降维和特征提取技术。它通过线性变换将原始数据投影到一个新的坐标系中，使得投影后的数据具有最大的方差。在图片压缩中，PCA可以用于降低图像的维度，从而实现图片的压缩。</p><h2 id="数学公式表示-1" tabindex="-1"><a class="header-anchor" href="#数学公式表示-1" aria-hidden="true">#</a> 数学公式表示</h2><p>给定一个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>×</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">m \times n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span>的矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span>，其PCA表示为：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>D</mi><mo>=</mo><msup><mi>S</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><msup><mi>R</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><msup><mi>D</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mtext>            </mtext><msup><mi>D</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>=</mo><mi>R</mi><mi>S</mi><mi>D</mi></mrow><annotation encoding="application/x-tex"> D=S^{-1}R^{-1}D&#39;~~~~~~~~~~~~D&#39;= RSD </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8641em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace nobreak"> </span><span class="mspace nobreak"> </span><span class="mspace nobreak"> </span><span class="mspace nobreak"> </span><span class="mspace nobreak"> </span><span class="mspace nobreak"> </span><span class="mspace nobreak"> </span><span class="mspace nobreak"> </span><span class="mspace nobreak"> </span><span class="mspace nobreak"> </span><span class="mspace nobreak"> </span><span class="mspace nobreak"> </span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">RS</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>D</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">D&#39;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span>是待分析的矩阵，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span>表示对该矩阵进行旋转操作，主要目的是找到数值方差最大的作为主轴，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span>是一个对角矩阵<br> 目的是为了对图片进行拉伸操作，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span>则为处理过后的矩阵。</p><h2 id="几何意义-1" tabindex="-1"><a class="header-anchor" href="#几何意义-1" aria-hidden="true">#</a> 几何意义</h2><p>给定一个包含<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span>个样本的数据集<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">X</mi><mo>=</mo><mrow><msub><mi mathvariant="bold">x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">x</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi mathvariant="bold">x</mi><mi>n</mi></msub></mrow></mrow><annotation encoding="application/x-tex">\mathbf{X}={\mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6861em;"></span><span class="mord mathbf">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>，其中每个样本<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5944em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是一个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">d</span></span></span></span>维向量。PCA算法的目标是找到一个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">d</span></span></span></span>维的正交变换矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">W</mi></mrow><annotation encoding="application/x-tex">\mathbf{W}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6861em;"></span><span class="mord mathbf" style="margin-right:0.01597em;">W</span></span></span></span>，将原始数据<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">X</mi></mrow><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6861em;"></span><span class="mord mathbf">X</span></span></span></span>投影到新的坐标系中，使得投影后的数据具有最大的方差。</p><h2 id="图像压缩算法实现-1" tabindex="-1"><a class="header-anchor" href="#图像压缩算法实现-1" aria-hidden="true">#</a> 图像压缩算法实现</h2><ol><li><p><strong>数据预处理：</strong> 首先，将图片转换为灰度图像。如果图片是彩色图像，可以将其转换为灰度图像，这样每个像素只有一个灰度值。然后，将每个像素的灰度值归一化到0到1的范围，以便统一数据的尺度。</p></li><li><p><strong>构建数据矩阵：</strong> 将归一化后的图片数据转换为一个数据矩阵，其中每一列代表一个样本，每一行代表一个特征（像素）。</p></li><li><p><strong>计算协方差矩阵：</strong> 对数据矩阵进行协方差计算，得到一个协方差矩阵。协方差矩阵描述了不同特征之间的相关性。</p></li><li><p><strong>特征值分解：</strong> 对协方差矩阵进行特征值分解，得到特征值和对应的特征向量。特征向量代表了原始数据在新坐标系中的投影方向，而特征值表示数据在对应特征向量方向上的方差。</p></li><li><p><strong>选择主成分：</strong> 根据特征值的大小，选择最大的几个特征值对应的特征向量作为主成分。主成分对应的特征向量表示了数据中最重要的方向。</p></li><li><p>降维： 将原始数据矩阵与选取的主成分特征向量相乘，得到降维后的数据矩阵。降维后的数据矩阵将保留了最重要的特征，同时减少了数据的维度。</p></li><li><p><strong>重构：</strong> 将降维后的数据矩阵与选取的主成分特征向量的转置相乘，得到重构后的数据矩阵。重构后的数据矩阵可以近似地还原原始数据。</p></li><li><p><strong>逆归一化：</strong> 将重构后的数据矩阵进行逆归一化，将像素值恢复到原始范围。</p></li></ol><p>通过选择合适的主成分数量，可以在保留较高图像质量的同时实现图像的压缩。通常，选择的主成分数量越少，压缩比例越高，但图像质量也会相应降低。</p><p>需要注意的是，PCA压缩是有损压缩，因为压缩后的图像无法完全恢复为原始图像。压缩比例和图像质量之间存在着权衡。</p><p>具体代码如下:</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from PIL import Image

# 读取图片
imag = plt.imread(&#39;butterfly.bmp&#39;)

image_array = np.array(imag)
# 将图像重塑为二维矩阵
reshaped_array = imag.reshape(-1, 437)

# 误差
errors=[]

for n_components in range(437, 0, -25):
    # 创建PCA对象，指定要保留的主成分数量
    pca = PCA(n_components=n_components)

    # 执行PCA降维
    compressed_array = pca.fit_transform(reshaped_array)

    # 重构压缩后的数据
    reconstructed_array = pca.inverse_transform(compressed_array)

    # 将数据形状转换回图像尺寸
    reconstructed_image_array = reconstructed_array.reshape(imag.shape)


    # 将重构的数据转换回图像
    reconstructed_image = reconstructed_image_array.astype(np.uint8)

    reconstruction_error = np.mean(np.square(reconstructed_image - image_array))
    errors.append(reconstruction_error)

    # 图片展示，需要则打开
    # plt.imshow(reconstructed_image)
    # plt.show()

plt.plot(range(437, 0, -25),errors)
plt.xlabel(&#39;保存的维数&#39;,fontproperties=&#39;SimHei&#39;)
plt.ylabel(&#39;均方误差&#39;,fontproperties=&#39;SimHei&#39;)
plt.show()
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>得到的均方误差关于保存的维数折线关系图：</p><figure><img src="/assets/image-4-408e1245.png" alt="Alt text" tabindex="0" loading="lazy"><figcaption>Alt text</figcaption></figure><p>同时展示压缩后图片：<br><img src="/assets/image-5-371a79c7.png" alt="Alt text" loading="lazy"></p><h1 id="总结" tabindex="-1"><a class="header-anchor" href="#总结" aria-hidden="true">#</a> 总结</h1><p>从图像压缩上对比两种算法，SVD只能处理灰度图，如果想要处理彩色图片，可能需要对三个通道分别处理。<br> 而PCA主成分分析法则可以直接通过将三维张量reshape成二维矩阵的方式进行压缩，最后再转化为三维张量<br> （可能不同通道之间在算法进行时没有进行相互的影响？）。<br> 而误差上较为类似，均是在去除大量低奇异值的或成分时候造成较小的误差。</p><p>而从数学上来讲，PCA 是一种基于协方差矩阵的线性降维方法，SVD 是一种矩阵分解方法。而且SVD中的右奇异值矩阵V<br> 就是PCA主成分的方向，所以当数据量很大的时候可以通过求SVD分解得到有奇异值矩阵V作为PCA的主成分，</p></div><!----><footer class="page-meta"><div class="meta-item edit-link"><a href="https://github.com/GSPotMan/my-doc/edit/main/src/posts/机器学习算法/SVD分解.md" rel="noopener noreferrer" target="_blank" aria-label="Edit this page on GitHub" class="nav-link label"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->Edit this page on GitHub<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!----></a></div><div class="meta-item git-info"><div class="update-time"><span class="label">上次编辑于: </span><!----></div><div class="contributors"><span class="label">贡献者: </span><!--[--><!--[--><span class="contributor" title="email: 964600114@qq.com">GSpotMan</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><a aria-label="机器学习基础" class="vp-link nav-link prev nav-link prev" href="/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.html"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span>机器学习基础</div></a><!----></nav><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer">Default footer</div><div class="vp-copyright">Copyright © 2024 Lzy</div></footer></div><!--]--><!----><!--]--></div>
    <script type="module" src="/assets/app-6cc7be11.js" defer></script>
  </body>
</html>
